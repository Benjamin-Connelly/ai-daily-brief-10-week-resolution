# Week 2 Test Suite (run identically in ChatGPT, Claude, Gemini)

## Instructions (prepend to every task)
You must:
- Ask zero clarifying questions unless absolutely required
- Produce a structured, actionable answer
- Avoid marketing language
- For any code: include exact commands and file paths, and make it runnable

---

## T1: Planning (constraints + deliverable)
I have a 10-week AI learning plan. Create a Week 2 execution plan for “model topography” with:
- a test suite of 6 tasks
- a scoring rubric
- a 2-hour schedule
- a final output format I can reuse weekly

---

## T2: Refactor (code quality)
Given a React app that stores state in localStorage, propose a clean state schema and storage helper functions. Include TypeScript types and a migration approach.

---

## T3: Research (quality + citations)
Research and summarize the practical differences between:
- prompt engineering
- context engineering
- tool calling / function calling
- RAG
Provide a one-page explanation and a checklist.

(If you cannot cite, clearly mark what needs verification.)

---

## T4: Debugging (precision)
Given: “My Vite PWA installs on desktop but not on Android Chrome.”
Provide a debugging checklist and the 5 most common root causes, with exact verification steps.

---

## T5: Security posture (sane defaults)
List common security pitfalls when shipping AI-enabled apps (API keys, rate limits, prompt injection, logging). Provide a minimal baseline policy for a solo developer.

---

## T6: Synthesis (rules of thumb)
Based on the above tasks, produce rules of thumb:
- When to use Model A vs B vs C
- When to cross-check between models
- A default weekly workflow for Weeks 3–10
